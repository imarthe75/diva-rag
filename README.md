Sistema de B√≥veda Digital con Ceph, Python y PostgreSQL

Este sistema permitir√° el almacenamiento seguro de archivos encriptados utilizando Ceph como backend de almacenamiento, gestionando la metadata en PostgreSQL y exponiendo una API RESTful para la interacci√≥n.

Digital Vault es una soluci√≥n robusta y moderna para la gesti√≥n segura y descentralizada de archivos digitales. Dise√±ado con una arquitectura de microservicios y tecnolog√≠as de vanguardia, este proyecto demuestra c√≥mo construir un sistema escalable y resiliente que prioriza la seguridad, la asincron√≠a y la eficiencia en el manejo de datos sensibles.

Caracter√≠sticas Principales:
API RESTful con Flask: Un backend potente y flexible desarrollado con Flask, ofreciendo endpoints intuitivos para la subida, descarga, eliminaci√≥n y gesti√≥n de metadatos de archivos.
Almacenamiento Descentralizado con MinIO/Ceph: Los archivos se almacenan de forma segura en un cl√∫ster de objetos compatible con S3 (MinIO, emulando Ceph), garantizando alta disponibilidad y escalabilidad.
Cifrado Robusto de Archivos: Cada archivo se cifra con una clave √∫nica (Fernet) antes de ser almacenado, y esta clave de cifrado se gestiona de forma segura, garantizando que solo los usuarios autorizados puedan acceder al contenido original.
Base de Datos PostgreSQL: Almacenamiento fiable de metadatos de archivos (nombres, ubicaciones, claves de cifrado) para una gesti√≥n y recuperaci√≥n eficientes.
Procesamiento As√≠ncrono con Celery y Redis/Valkey: Las tareas intensivas, como el cifrado y el procesamiento post-subida, se delegan a workers de Celery, utilizando Redis (o Valkey) como broker, lo que asegura que la API responda r√°pidamente y el procesamiento se realice en segundo plano.
Comunicaci√≥n de Eventos con Apache Kafka: Implementaci√≥n de un productor de Kafka para publicar eventos de subida de archivos, permitiendo la integraci√≥n con futuros servicios que necesiten reaccionar a la actividad del sistema.
Contenedorizaci√≥n con Docker Compose: Todos los componentes de la infraestructura (MinIO, PostgreSQL, Redis/Valkey, Zookeeper, Kafka, Celery Worker) se orquestan f√°cilmente con Docker Compose, facilitando la configuraci√≥n del entorno de desarrollo.
Dise√±o Modular y Escalable: La arquitectura de microservicios permite escalar componentes de forma independiente y facilita el desarrollo y mantenimiento.

Justificaci√≥n de Tecnolog√≠as
Ceph: Es una excelente elecci√≥n para el almacenamiento de objetos distribuidos. Proporciona alta disponibilidad, escalabilidad y tolerancia a fallos, lo que lo hace ideal para una b√≥veda digital donde la durabilidad de los archivos es cr√≠tica. Utilizaremos el protocolo S3 (compatible con Ceph Rados Gateway) para interactuar con √©l, lo cual simplifica la integraci√≥n.
Python: Es el lenguaje m√°s adecuado para este tipo de servicio por varias razones:
  Madurez de Bibliotecas: Cuenta con bibliotecas robustas para todas las necesidades:
  boto3: Para interactuar con Ceph (a trav√©s de la API S3).
  psycopg2 o SQLAlchemy: Para la interacci√≥n con PostgreSQL.
  cryptography: Para el manejo de encriptaci√≥n y desencriptaci√≥n robusta.
  Flask o FastAPI: Para construir la API REST de manera eficiente y escalable.
Productividad: Su sintaxis clara y concisa permite un desarrollo r√°pido.
Comunidad y Soporte: Amplia comunidad y recursos disponibles.
Rendimiento: Suficiente para este tipo de aplicaci√≥n, especialmente cuando se delega el almacenamiento a Ceph y la base de datos a PostgreSQL.

PostgreSQL: Es una base de datos relacional de objetos muy potente y confiable, ideal para almacenar la metadata de los archivos.
Soporte JSON/JSONB: Su capacidad para almacenar datos en formatos JSON o JSONB es perfecta para la metadata variable de los archivos. JSONB es preferible por su eficiencia en el almacenamiento y las consultas indexadas.
Robustez y Transaccionalidad: Garantiza la integridad de los datos.
Seguridad: Ofrece caracter√≠sticas de seguridad avanzadas.

Kafka: El uso de Kafka en tu b√≥veda digital puede ser muy √∫til y beneficioso si:
Esperas un volumen significativo de subidas/descargas/operaciones.
Necesitas realizar m√∫ltiples tipos de procesamiento sobre los archivos (indexaci√≥n, OCR, an√°lisis de seguridad, etc.).
Buscas una alta escalabilidad y desacoplamiento entre los componentes de tu arquitectura.
Requiere auditor√≠a robusta y trazabilidad de eventos.
Necesitas integrar la b√≥veda con otros sistemas empresariales.
Si tus requisitos son m√°s modestos, la complejidad de Kafka podr√≠a ser excesiva. Pero para una soluci√≥n "completa" y preparada para el futuro, Kafka es un componente estrat√©gico que habilita capacidades que ser√≠an dif√≠ciles de lograr de otra manera.

Valkey (o Redis) para Caching y Sesiones:
Para qu√©: Como mencionamos, Valkey es excelente para caching (evitar consultas repetitivas a la base de datos para datos frecuentemente accedidos como metadatos de archivos), gesti√≥n de sesiones de usuario (almacenar tokens de autenticaci√≥n), y como broker para Celery (si decides implementar tareas en segundo plano m√°s avanzadas).
Beneficio: Mejora el rendimiento de la API al reducir la carga en PostgreSQL y proporciona un almacenamiento temporal r√°pido. Ya tienes PostgreSQL para datos persistentes y Kafka para eventos, Valkey llenar√≠a el rol de almacenamiento "r√°pido y vol√°til".

Celery (con Valkey/Redis o RabbitMQ como Broker):
Para qu√©: Es un sistema de colas de tareas distribuidas. Perfecto para las tareas as√≠ncronas que hablamos de poner en tu consumidor de Kafka.
Beneficio: Te permite ejecutar tareas que consumen mucho tiempo (como escaneo de virus, transcodificaci√≥n, generaci√≥n de miniaturas) en procesos separados, liberando tu API para responder r√°pidamente a los usuarios. Los eventos de Kafka pueden disparar estas tareas de Celery.

M√≥dulo de Encriptaci√≥n/Desencriptaci√≥n
Utilizar la librer√≠a cryptography.fernet o cryptography.hazmat.primitives.ciphers para una encriptaci√≥n sim√©trica robusta (ej. AES en modo GCM).
Clave de encriptaci√≥n por archivo: Cada archivo debe tener una clave de encriptaci√≥n √∫nica. Esto es crucial para la seguridad: si una clave se compromete, solo un archivo se ve afectado.
Clave Maestra del Sistema: Una clave maestra (o un par de claves asim√©tricas) debe ser utilizada para encriptar las claves individuales de los archivos antes de almacenarlas en PostgreSQL. Esta clave maestra debe ser gestionada de forma extremadamente segura (ej. variables de entorno, HashiCorp Vault, AWS Secrets Manager, etc.).

Proceso de Encriptaci√≥n:
Generar una clave sim√©trica para el archivo (ej., Fernet.generate_key()).
Inicializar el objeto de encriptaci√≥n con esta clave.
Encriptar el contenido del archivo.
Encriptar la clave sim√©trica del archivo usando la clave maestra del sistema.
Almacenar la clave sim√©trica encriptada en PostgreSQL.

Proceso de Desencriptaci√≥n:
Recuperar la clave sim√©trica encriptada desde PostgreSQL.
Desencriptar la clave sim√©trica del archivo usando la clave maestra del sistema.
Descargar el archivo encriptado de Ceph.
Desencriptar el archivo usando la clave sim√©trica.

M√≥dulo de Interacci√≥n con Ceph (S3)
Utilizar boto3, el SDK de AWS para Python, que es compatible con Ceph S3.
Configurar el cliente boto3 para apuntar al endpoint de Ceph Rados Gateway, en lugar de AWS S3.
Funciones para subir (put_object), descargar (get_object) y eliminar (delete_object) archivos.

M√≥dulo de Interacci√≥n con PostgreSQL
Utilizar psycopg2 directamente o un ORM como SQLAlchemy para una gesti√≥n de base de datos m√°s abstracta y robusta.



¬øPor qu√© Digital Vault?
Este proyecto es ideal para desarrolladores y equipos que buscan entender o implementar:

Arquitecturas de microservicios.
Patrones de cifrado de datos en tr√°nsito y en reposo.
Uso de almacenamiento de objetos distribuido.
Sistemas de colas de mensajes (Kafka) para comunicaci√≥n as√≠ncrona.
Procesamiento de tareas en segundo plano (Celery).
Despliegues con Docker Compose para entornos de desarrollo.

![image](https://github.com/user-attachments/assets/9cc1be91-94df-4544-af57-6c7839f47878)

¬°Explora el c√≥digo, contribuye o ad√°ptalo a tus propias necesidades!

üöÄ Instalaci√≥n y Configuraci√≥n
Sigue estos pasos para poner en marcha el proyecto en tu entorno de desarrollo.

1. Clonar el Repositorio
Bash
git clone https://github.com/tu_usuario/digital_vault_project.git
cd digital_vault_project

2. Configurar Variables de Entorno
Crea un archivo .env en la ra√≠z del proyecto (junto a docker-compose.yml) y configura las siguientes variables. Puedes usar nuevo1.env como plantilla si lo tienes.

.env:

Fragmento de c√≥digo

# Configuraci√≥n del Backend (Flask) y PostgreSQL
POSTGRES_DB=digital_vault_db
POSTGRES_USER=dvu
POSTGRES_PASSWORD=testpass # Aseg√∫rate de que coincida con tu instalaci√≥n nativa de PostgreSQL
POSTGRES_HOST=localhost # ¬°Importante! Para tu instalaci√≥n nativa de Windows
POSTGRES_PORT=5432

# Configuraci√≥n de Valkey (Redis)
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Configuraci√≥n de MinIO/Ceph
CEPH_ENDPOINT_URL=http://localhost:9000
CEPH_ACCESS_KEY=minioadmin # Clave por defecto de MinIO
CEPH_SECRET_KEY=minioadmin # Clave por defecto de MinIO
CEPH_BUCKET_NAME=digital-vault-bucket

# Clave Maestra del Sistema (Fernet) - Genera una con `from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())`
SYSTEM_MASTER_KEY=TU_CLAVE_FERNET_BASE64_AQUI=

# Configuraci√≥n de Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
3. Levantar Servicios con Docker Compose
Navega a la ra√≠z del proyecto donde se encuentra docker-compose.yml y levanta todos los servicios. Aseg√∫rate de que Docker Desktop est√© corriendo.

Bash

docker-compose up -d --build
Esto levantar√° los siguientes servicios:

zookeeper (para Kafka)
kafka (broker de mensajes)
valkey (broker y backend de resultados para Celery)
minio (almacenamiento de objetos compatible con S3)
celery_worker (procesa tareas as√≠ncronas)

4. Configurar PostgreSQL
Si a√∫n no lo has hecho:

Aseg√∫rate de que tu instancia de PostgreSQL nativa en Windows est√© corriendo y acepte conexiones en el puerto 5432.
Crea la base de datos digital_vault_db y el usuario dvu con la contrase√±a testpass.

Puedes hacerlo conect√°ndote a psql (o pgAdmin) y ejecutando:

SQL

CREATE DATABASE digital_vault_db;
CREATE USER dvu WITH PASSWORD 'testpass';
GRANT ALL PRIVILEGES ON DATABASE digital_vault_db TO dvu;
Ejecuta las migraciones de la base de datos (crear tablas):

Estructura de la tabla files (ejemplo):

SQL

CREATE TABLE files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL, -- O INT si tus IDs de usuario son enteros
    ceph_path TEXT NOT NULL, -- Ruta o clave del objeto en Ceph
    encryption_key_encrypted BYTEA NOT NULL, -- Clave de encriptaci√≥n del archivo, encriptada con la clave maestra
    original_filename TEXT NOT NULL,
    mimetype TEXT,
    size_bytes BIGINT,
    upload_timestamp TIMESTAMPTZ DEFAULT NOW(),
    metadata JSONB, -- Almacena la metadata variable del archivo
    CONSTRAINT fk_user
        FOREIGN KEY(user_id)
        REFERENCES users(id) -- Si tienes una tabla de usuarios
);

-- Tabla de usuarios (opcional, pero recomendada)
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(255) UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    email VARCHAR(255) UNIQUE,
    created_at TIMESTAMPTZ DEFAULT NOW()
);


Navega a la carpeta backend e instala las dependencias de Python:

Bash

cd backend
pip install -r requirements.txt
Luego, ejecuta el script de inicializaci√≥n de la base de datos (si tienes uno, por ejemplo, init_db.py o directamente desde app.py si tiene una funci√≥n de inicializaci√≥n de tablas):

Bash

python -c "from app import create_tables; create_tables()" # Asumiendo que create_tables() est√° en app.py
(Si no tienes una funci√≥n create_tables separada, deber√≠as agregarla a app.py o ejecutar las sentencias SQL para crear la tabla files manualmente.)

5. Iniciar la Aplicaci√≥n Flask (Backend)
Desde la carpeta backend:

Bash

python app.py
La aplicaci√≥n Flask se ejecutar√° en http://127.0.0.1:5000 (o http://localhost:5000).

üõ†Ô∏è Estructura del Proyecto
El proyecto se organiza de la siguiente manera:

/: Contiene el docker-compose.yml, .env y el Dockerfile principal.
backend/: Contiene la l√≥gica del backend de Flask.
app.py: La aplicaci√≥n Flask principal, rutas, l√≥gica de autenticaci√≥n y conexi√≥n a servicios.
tasks.py: Definiciones de tareas Celery para procesamiento as√≠ncrono.
minio_client.py: M√≥dulo para interactuar con MinIO/Ceph.
kafka_producer.py: M√≥dulo para producir mensajes a Kafka.
db.py: L√≥gica de conexi√≥n y operaciones con la base de datos PostgreSQL. (Podr√≠as considerar mover get_db_connection y la l√≥gica de creaci√≥n de tablas aqu√≠)
utils.py: Funciones de utilidad (ej. cifrado/descifrado).
requirements.txt: Dependencias de Python para el backend y Celery.
Dockerfile: Define la imagen Docker para el Celery worker.

frontend/ (Si existe): Contiene el c√≥digo de la interfaz de usuario.
![image](https://github.com/user-attachments/assets/996b4710-2a36-4a03-bfd7-1f3166afb0d6)

üöÄ Uso de la API (Ejemplos con Postman/cURL)
La API opera en http://127.0.0.1:5000.

![image](https://github.com/user-attachments/assets/d64c2d54-f6b6-43f1-802b-ee6f7816d0eb)


1. Subir un Archivo (POST)
Sube un archivo, cifr√°ndolo y almacenando sus metadatos.

URL: http://127.0.0.1:5000/vault/upload

M√©todo: POST

Headers:
Content-Type: multipart/form-data

Body (form-data):
file: Selecciona el archivo que deseas subir.
user_id: [ID del usuario que sube el archivo, ej., default_user]
original_filename: [Nombre original del archivo, ej., documento.pdf]

![image](https://github.com/user-attachments/assets/fa158202-4532-42aa-aecc-62a2d50271ef)


2. Obtener Metadatos de un Archivo (GET)
Recupera los metadatos de un archivo espec√≠fico.

URL: http://127.0.0.1:5000/vault/metadata/{file_id}?user_id=[user_id]

M√©todo: GET

Ejemplo: http://127.0.0.1:5000/vault/metadata/a0fb4e20-9440-4d15-94df-979f8f42a2a3?user_id=default_user

![image](https://github.com/user-attachments/assets/c4752147-5ef5-4e2c-8411-48d6fc4b329a)


3. Descargar un Archivo (GET)
Descarga un archivo previamente subido, que ser√° descifrado al vuelo.

URL: http://127.0.0.1:5000/vault/{file_id}?user_id=[user_id]

M√©todo: GET

Ejemplo: http://127.0.0.1:5000/vault/a0fb4e20-9440-4d15-94df-979f8f42a2a3?user_id=default_user

![image](https://github.com/user-attachments/assets/5bb6f300-a33b-44ad-99f4-983ab8817b52)


4. Listar Archivos por Usuario (GET)
Obtiene una lista de todos los archivos asociados a un user_id espec√≠fico.

URL: http://127.0.0.1:5000/vault/user/{user_id}?requester_id=[requester_id]

M√©todo: GET

Ejemplo: http://127.0.0.1:5000/vault/user/default_user?requester_id=admin

5. Eliminar un Archivo (DELETE)
Elimina un archivo del almacenamiento y sus metadatos de la base de datos.

URL: http://127.0.0.1:5000/vault/{file_id}?user_id=[user_id]

M√©todo: DELETE

Ejemplo: http://127.0.0.1:5000/vault/a0fb4e20-9440-4d15-94df-979f8f42a2a3?user_id=default_user

Consideraciones de Seguridad Adicionales
Autenticaci√≥n y Autorizaci√≥n: Implementar un sistema de autenticaci√≥n (ej., JWT) y autorizaci√≥n basado en roles/permisos para controlar qui√©n puede subir, descargar o eliminar archivos.
Gesti√≥n de Claves: La clave maestra del sistema (para encriptar las claves de los archivos) es el punto m√°s cr√≠tico. NUNCA debe estar en el c√≥digo fuente ni ser accedida directamente por usuarios. Considera usar un servicio de gesti√≥n de secretos.
Comunicaci√≥n Segura: Todas las comunicaciones (entre el cliente web y el servicio, y entre el servicio y Ceph/PostgreSQL) deben ser sobre HTTPS/TLS.
Validaci√≥n de Entradas: Validar todas las entradas de usuario para prevenir inyecciones SQL, ataques XSS, etc.
Auditor√≠a y Logs: Registrar todas las operaciones importantes (subidas, descargas, eliminaciones, intentos de acceso fallidos) para prop√≥sitos de auditor√≠a y detecci√≥n de anomal√≠as.
Respaldo: Implementar una estrategia de respaldo tanto para Ceph como para PostgreSQL.


ü§ù Contribuciones
Las contribuciones son bienvenidas. Si tienes sugerencias de mejora, nuevas caracter√≠sticas o encuentras alg√∫n bug, por favor:

Haz un "fork" del repositorio.

Crea una nueva rama (git checkout -b feature/nueva-caracteristica o bugfix/solucion-bug).

Realiza tus cambios y commitea (git commit -m 'feat: A√±ade nueva caracter√≠stica').

Haz "push" a tu rama (git push origin feature/nueva-caracteristica).

Abre un "Pull Request" explicando tus cambios.

Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.
